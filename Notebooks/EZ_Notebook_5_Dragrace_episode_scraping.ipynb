{"cells":[{"cell_type":"markdown","id":"43bcf3d5","metadata":{"id":"43bcf3d5"},"source":["# This notebook scrapes 'Drag Race' episode data."]},{"cell_type":"markdown","id":"1d1db342","metadata":{"id":"1d1db342"},"source":["installing the beautiful soup package for scraping and other libraries for accessing URLs"]},{"cell_type":"code","execution_count":null,"id":"80500515","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4549,"status":"ok","timestamp":1688652503045,"user":{"displayName":"Eszter Zsisku","userId":"05092016175184633832"},"user_tz":-60},"id":"80500515","outputId":"579aff6b-e865-4c39-c484-521b5c79df43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n"]}],"source":["!pip install requests beautifulsoup4"]},{"cell_type":"code","execution_count":null,"id":"b28d3fa9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5620,"status":"ok","timestamp":1688652508658,"user":{"displayName":"Eszter Zsisku","userId":"05092016175184633832"},"user_tz":-60},"id":"b28d3fa9","outputId":"08cf9c0e-7e64-4ede-e448-853716514dcf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting requests_html\n","  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.27.1)\n","Collecting pyquery (from requests_html)\n","  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n","Collecting fake-useragent (from requests_html)\n","  Downloading fake_useragent-1.1.3-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting parse (from requests_html)\n","  Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n","Collecting bs4 (from requests_html)\n","  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting w3lib (from requests_html)\n","  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n","Collecting pyppeteer>=0.0.14 (from requests_html)\n","  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n","Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (2023.5.7)\n","Collecting importlib-metadata>=1.4 (from pyppeteer>=0.0.14->requests_html)\n","  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n","Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests_html)\n","  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.65.0)\n","Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.26.16)\n","Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests_html)\n","  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests_html) (4.11.2)\n","Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests_html) (4.9.2)\n","Collecting cssselect>=1.2.0 (from pyquery->requests_html)\n","  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->requests_html) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests_html) (3.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.15.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests_html) (2.4.1)\n","Building wheels for collected packages: bs4\n","  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=f17559ff2a0d1c30aa947c563fb2c901bf25707e6d8497574c6f09a17d7db554\n","  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n","Successfully built bs4\n","Installing collected packages: pyee, parse, fake-useragent, websockets, w3lib, importlib-metadata, cssselect, pyquery, pyppeteer, bs4, requests_html\n","Successfully installed bs4-0.0.1 cssselect-1.2.0 fake-useragent-1.1.3 importlib-metadata-6.7.0 parse-1.19.1 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests_html-0.10.0 w3lib-2.1.1 websockets-10.4\n"]}],"source":["!pip install requests_html"]},{"cell_type":"code","execution_count":null,"id":"71a43cac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6039,"status":"ok","timestamp":1688652514688,"user":{"displayName":"Eszter Zsisku","userId":"05092016175184633832"},"user_tz":-60},"id":"71a43cac","outputId":"a7dd00dc-bba1-43a6-e88e-68d44300946f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-docx\n","  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.2)\n","Building wheels for collected packages: python-docx\n","  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=bb2222f3dc489d4c420c899a583fcef1c009dfedaadd921cbb1b60a9b757cc6f\n","  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n","Successfully built python-docx\n","Installing collected packages: python-docx\n","Successfully installed python-docx-0.8.11\n"]}],"source":["!pip install python-docx"]},{"cell_type":"markdown","id":"3e18cc32","metadata":{"id":"3e18cc32"},"source":["Importing required libraries and modules and scraping transcript from URL."]},{"cell_type":"code","execution_count":null,"id":"9d3bbcef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4428,"status":"ok","timestamp":1688597024451,"user":{"displayName":"Eszter Zsisku","userId":"05092016175184633832"},"user_tz":-60},"id":"9d3bbcef","outputId":"70448609-41d1-49d0-ff8a-1b6dda73dbad"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"name":"stdout","output_type":"stream","text":["                                               Sentence\n","0         [static]\\nLooking for a new\\npolitical party?\n","1                  Are you tired\\nof politics as usual?\n","2     I'm Donald Trump,\\nand I do not approve\\nthis ...\n","3                   Join the RuPaul's\\nDrag Race party!\n","4     ♪ I am American... ♪\\nLife, liberty,\\nand the ...\n","...                                                 ...\n","1084                                       Bitch, what?\n","1085                                  -What's going on?\n","1086                                 -What's happening?\n","1087  I hope these bitches are\\nready to eat the lef...\n","1088  ♪ I am American,\\nAmerican, American ♪\\n♪ I am...\n","\n","[1089 rows x 1 columns]\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","\n","# URL of the webpage\n","url = \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-1-Im_That_Bitch\"\n","\n","# Send a GET request to the URL\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","response.raise_for_status()\n","\n","# Create a BeautifulSoup object to parse the HTML content\n","soup = BeautifulSoup(response.content, 'html.parser')\n","\n","# Find the specific <div> tag with the class name \"full-script\"\n","div_tag = soup.find(\"div\", class_=\"full-script\")\n","\n","# Check if the <div> tag exists\n","if div_tag:\n","    # Extract the text within the <div> tag\n","    text = div_tag.get_text(\"\\n\", strip=True)\n","\n","    # Tokenize the text into sentences\n","    sentences = nltk.sent_tokenize(text)\n","\n","    # Create a dataframe from the sentences\n","    df = pd.DataFrame(sentences, columns=[\"Sentence\"])\n","\n","    # Display the dataframe\n","    print(df)\n","else:\n","    print(\"The <div> tag with the class name 'full-script' was not found.\")\n"]},{"cell_type":"code","execution_count":null,"id":"bc9720eb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1688597031489,"user":{"displayName":"Eszter Zsisku","userId":"05092016175184633832"},"user_tz":-60},"id":"bc9720eb","outputId":"16c3d454-3cc0-42c4-8768-2f336aa94381"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-b05cc031-90df-4ae3-8aa3-05625e3ef646\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[static]\\nLooking for a new\\npolitical party?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Are you tired\\nof politics as usual?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I'm Donald Trump,\\nand I do not approve\\nthis ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Join the RuPaul's\\nDrag Race party!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>♪ I am American... ♪\\nLife, liberty,\\nand the ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1084</th>\n","      <td>Bitch, what?</td>\n","    </tr>\n","    <tr>\n","      <th>1085</th>\n","      <td>-What's going on?</td>\n","    </tr>\n","    <tr>\n","      <th>1086</th>\n","      <td>-What's happening?</td>\n","    </tr>\n","    <tr>\n","      <th>1087</th>\n","      <td>I hope these bitches are\\nready to eat the lef...</td>\n","    </tr>\n","    <tr>\n","      <th>1088</th>\n","      <td>♪ I am American,\\nAmerican, American ♪\\n♪ I am...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1089 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b05cc031-90df-4ae3-8aa3-05625e3ef646')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b05cc031-90df-4ae3-8aa3-05625e3ef646 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b05cc031-90df-4ae3-8aa3-05625e3ef646');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               Sentence\n","0         [static]\\nLooking for a new\\npolitical party?\n","1                  Are you tired\\nof politics as usual?\n","2     I'm Donald Trump,\\nand I do not approve\\nthis ...\n","3                   Join the RuPaul's\\nDrag Race party!\n","4     ♪ I am American... ♪\\nLife, liberty,\\nand the ...\n","...                                                 ...\n","1084                                       Bitch, what?\n","1085                                  -What's going on?\n","1086                                 -What's happening?\n","1087  I hope these bitches are\\nready to eat the lef...\n","1088  ♪ I am American,\\nAmerican, American ♪\\n♪ I am...\n","\n","[1089 rows x 1 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","id":"8f58915a","metadata":{"id":"8f58915a"},"source":["Scraping further episode transcripts and appending them to the dataframe."]},{"cell_type":"code","execution_count":null,"id":"8ccf67db","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18451,"status":"ok","timestamp":1688652765217,"user":{"displayName":"Eszter Zsisku","userId":"05092016175184633832"},"user_tz":-60},"id":"8ccf67db","outputId":"4024cbb4-1f16-4fdb-b3bf-ee1f1bb73a2a"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"name":"stdout","output_type":"stream","text":["                                                Sentence\n","0          [static]\\nLooking for a new\\npolitical party?\n","1                   Are you tired\\nof politics as usual?\n","2      I'm Donald Trump,\\nand I do not approve\\nthis ...\n","3                    Join the RuPaul's\\nDrag Race party!\n","4      ♪ I am American... ♪\\nLife, liberty,\\nand the ...\n","...                                                  ...\n","18767  ♪ I'm a winner, baby ♪\\n♪ I'm a winner ♪\\n♪ I'...\n","18768                      Can I get an amen up in here?\n","18769                                              Amen!\n","18770                            Now let the music play.\n","18771  ♪ I'm a winner ♪\\n♪ I'm a winner, baby ♪\\n♪ I'...\n","\n","[18772 rows x 1 columns]\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","\n","# List of URLs\n","urls = [\"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-1-Im_That_Bitch\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-9-Choices_2020\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-10-Superfan_Makeover\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-11-One-Queen_Show\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-12-Viva_Drag_Vegas\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-13-Reunited_Alone_Together\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-12/episode-14-Grand_Finale\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-13/episode-10-Snatch_Game\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-5-Save_a_Queen\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-6-Glamazon_Prime\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-7-The_Daytona_Wind\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-8-Episode_148\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-10-Snatch_Game\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-11-An_Extra_Special_Episode\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-13-The_Ross_Mathews_Roast\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-14-Catwalk\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-15-Reunited\",\n","        \"https://subslikescript.com/series/RuPauls_Drag_Race-1353056/season-14/episode-16-Grand_Finale\"]\n","\n","\n","\n","# Initialize an empty list to store sentences\n","all_sentences = []\n","\n","# Iterate over the URLs\n","for url in urls:\n","    # Send a GET request to the URL\n","    response = requests.get(url)\n","\n","    # Check if the request was successful\n","    if response.status_code == 200:\n","        # Create a BeautifulSoup object to parse the HTML content\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","\n","        # Find the specific <div> tag with the class name \"full-script\"\n","        div_tag = soup.find(\"div\", class_=\"full-script\")\n","\n","        # Check if the <div> tag exists\n","        if div_tag:\n","            # Extract the text within the <div> tag\n","            text = div_tag.get_text(\"\\n\", strip=True)\n","\n","            # Tokenize the text into sentences\n","            sentences = nltk.sent_tokenize(text)\n","\n","            # Add the sentences to the list\n","            all_sentences.extend(sentences)\n","        else:\n","            print(f\"The <div> tag with the class name 'full-script' was not found for URL: {url}\")\n","    else:\n","        print(f\"Failed to retrieve data from URL: {url}\")\n","\n","# Create a dataframe from the sentences\n","df = pd.DataFrame(all_sentences, columns=[\"Sentence\"])\n","\n","# Display the dataframe\n","print(df)\n"]},{"cell_type":"markdown","id":"060121a4","metadata":{"id":"060121a4"},"source":["Downloading csv file of transcript."]},{"cell_type":"code","execution_count":null,"id":"dbfb6b43","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1688652922593,"user":{"displayName":"Eszter Zsisku","userId":"05092016175184633832"},"user_tz":-60},"id":"dbfb6b43","outputId":"52da8bb4-cfc7-4607-f668-9295a1c416df"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_4110075e-00c0-40e9-b5a9-680652099a71\", \"drag_transcript.csv\", 905793)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","\n","# Assuming you have a DataFrame called df\n","\n","# Save the DataFrame as a CSV file\n","df.to_csv('drag_transcript.csv', index=False)\n","\n","# Download the CSV file\n","files.download('drag_transcript.csv')"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}